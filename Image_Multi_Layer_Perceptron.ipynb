{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySrjEI-ra8Ix"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "6436c34c3bbb43a18db86caf0947694d",
      "0f65f40c41854f28a112a9d2c978ce8c",
      "2e0267a35bc943ed9332a1cb8ee65f2e",
      "0f0668fc44fc4eadb9433a85a5dbb495",
      "2eff22b3656b425cbee382f8df76906c",
      "14812b6862c049fb8585bfeb19f7c1cb",
      "1694cb34f5b54b39a689524387714452",
      "ac82629c4a1c475e9492cd900c962e92",
      "3c7055c92edb42d8b359d79073dffb22",
      "2271dc6cf33a490fa78971eb2e3d9524",
      "9b876d0504e149a2a5da7e520f5ac1d7",
      "e3235e3b6efe4ea28adb5e86a3dc57de",
      "eabf9f7ead5c4869b4307df0ed569e21",
      "cc8b7a7516864f3ca492fb4efdc0f29a",
      "decfafeeeb98493982d5848de74ebffe",
      "339f81912f3643d3b15dbc89e6e1418f",
      "c221be024f9b49309c910f3d30004369",
      "c1b960f659984cd9972601d4332d5acd",
      "94e7476189fa4287a12235a7025eb303",
      "23fd462888f64e03a089309950af4358",
      "ef28b46e590442f5be6a15091c44a08e",
      "d6ac7d994b084aa1bcffb5200dc6a93e",
      "c02d180095e94e2599f26fd448a1d535",
      "fec3cc59169c4e44990a20be63f3f677",
      "779c3a8be5d448d2b1ccd824b5fdeb98",
      "055b84c78a52438a83f1913a6c95af5e",
      "b7a459edf244407797f39c5a79ff26d3",
      "34dda88653cb415dbde32bef46bb5e4f",
      "0750652d011b416eb1c442e12d235a73",
      "6d1302d2760340b2af676590d82ff6bd",
      "86bdaebe4b50452198f9858d39a9d8ea",
      "91bff80a2a074aa3bc1f65fdae298095",
      "a1b37cc9b99947dab8b86be65476108e",
      "471a397c6f604d80a02f1eb15ee42963",
      "b6a10533c5b04977b7211d2eb2699839",
      "82e2a2e169b243a085802e70b812b424",
      "ab2544a283ab4854a2a4e6a647d6719e",
      "e53b352c750941e598cd376f3c56320e",
      "7a748956f761456587b2eedd39b59185",
      "40e4b04e00c74687abd393f8e0890158",
      "b82a633f72034c99bea2d69b37db0d93",
      "d48620dae0114e799e5b631711710826",
      "7a44716d53a14dacac427f20fdda8198",
      "c8732010814f43119e74f16af882e261"
     ]
    },
    "executionInfo": {
     "elapsed": 1678,
     "status": "ok",
     "timestamp": 1678768935577,
     "user": {
      "displayName": "NH L",
      "userId": "13973463595760031265"
     },
     "user_tz": 240
    },
    "id": "xhvD02tSbMCn",
    "outputId": "1648229d-7db2-409f-8b9d-c4aeeb907aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6436c34c3bbb43a18db86caf0947694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3235e3b6efe4ea28adb5e86a3dc57de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02d180095e94e2599f26fd448a1d535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471a397c6f604d80a02f1eb15ee42963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # cuda~GPU - faster processing speeds to CPU\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784  # 28*28  The image\n",
    "hidden_size = 500 # The layers that transform into output usable format\n",
    "num_classes = 10 # The # of labels for images\n",
    "num_epochs = 5 # Number of complete traversals through train set\n",
    "batch_size = 100 # Amt of samples fed through\n",
    "learning_rate = 0.001   # step size\n",
    "\n",
    "# MNIST dataset - creating training and testing set\n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader - loading training and testing set with designated batch size\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOjjJLrXbST-"
   },
   "outputs": [],
   "source": [
    "# Define a fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    # define the layers\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)   # Uses linear func to tansform data - 784 dimension to 500 dimension\n",
    "        self.relu = nn.ReLU() # Non-linear activation function transforming data, but keeping same dimensions\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # Uses linear func to transform data - 500 dimension to 10 dimension\n",
    "        # the 10  dimensions equates to the number of labels (classes) we have\n",
    "    \n",
    "    # tell the model how to process input sample x\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x) # Process input layer\n",
    "        out = self.relu(out) # Process hidden layer\n",
    "        out = self.fc2(out) # Process output layer\n",
    "        return out # Return output of each model layer\n",
    "\n",
    "# instantiate the model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device) # Create actual model using NeuralNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71963,
     "status": "ok",
     "timestamp": 1678769040851,
     "user": {
      "displayName": "NH L",
      "userId": "13973463595760031265"
     },
     "user_tz": 240
    },
    "id": "6TlkAlMCbWcX",
    "outputId": "6559be26-1bac-43ea-b24f-59a5866f1b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2890\n",
      "Epoch [1/5], Step [200/600], Loss: 0.3048\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1530\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1874\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1634\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1737\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0324\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0785\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0763\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1230\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0708\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0726\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0765\n",
      "Epoch [3/5], Step [200/600], Loss: 0.1053\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0423\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0793\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0321\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0919\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0523\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0464\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0658\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0328\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0436\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0525\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0297\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0621\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0332\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0285\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0153\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0336\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()   # define the loss computation method (not computed yet!)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)    # put model parameters into the optimizer; lr is \"learning rate\", which is the gradient descent \"step size\"\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs): # Loop through until epochs are finished on loaded train set\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device) # setting up images for input layer\n",
    "        labels = labels.to(device) # labels for the corresponding image\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images) # run image through neural net to process and predict\n",
    "        loss = criterion(outputs, labels) # Compute the difference between prediction and label as the loss (i.e., \"objective\" or \"cost\")\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()   # important!!!\n",
    "        loss.backward()   # compute gradient\n",
    "        optimizer.step()  # update parameters with gradient descent\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1677,
     "status": "ok",
     "timestamp": 1678769059544,
     "user": {
      "displayName": "NH L",
      "userId": "13973463595760031265"
     },
     "user_tz": 240
    },
    "id": "gDR7SA1KbtVP",
    "outputId": "f2db03d4-4469-4ec8-c307-769c6a51c3c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.63 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)  # actual label for images\n",
    "        outputs = model(images) # produce outputs (labels) of images from  model\n",
    "        _, predicted = torch.max(outputs.data, 1) # model predicted labels for  images\n",
    "        total += labels.size(0) \n",
    "        correct += (predicted == labels).sum().item() # Checking whether predictions on images were correct\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLkQyi8N0+NSF8OTu9hYf6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
