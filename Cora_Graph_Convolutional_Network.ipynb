{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uLYQDNJjXn7c"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden = 16                                     # hidden dimension\n",
    "dropout = 0.5\n",
    "lr = 0.01 \n",
    "weight_decay = 5e-4\n",
    "fastmode = 'store_true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6512,
     "status": "ok",
     "timestamp": 1649778353710,
     "user": {
      "displayName": "NH L",
      "userId": "13973463595760031265"
     },
     "user_tz": 240
    },
    "id": "SFa73PGvX-bu",
    "outputId": "0b028922-d1c8-44ac-8754-a4d4087b9c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora dataset...\n"
     ]
    }
   ],
   "source": [
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "def  load_data(path=\"./\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), # read node labels\n",
    "                                        dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)  # read node features\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])                        # one-hot encoding for labels\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)                \n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),       # read edge information\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "    features = normalize(features)                                            # feature normalization\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))                               # edge normalization\n",
    "\n",
    "    idx_train = range(140)                                                    # training set\n",
    "    idx_val = range(200, 500)                                                 # validation set\n",
    "    idx_test = range(500, 1500)                                               # testing set\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)                               # get adjacency matrix\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "                                                           \n",
    "    return adj, features, labels, idx_train, idx_val, idx_test          \n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ObvNpbnwZ5gW"
   },
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):                            \n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        # Please implement this function\n",
    "        output = torch.mm(input, self.weight)\n",
    "        output = torch.mm(adj, output)\n",
    "        return output + self.bias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "\n",
    "class GCN(nn.Module):                                             # a two-layer GCN\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = torch.nn.functional.relu(self.gc1(x, adj))\n",
    "        x = torch.nn.functional.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return torch.nn.functional.log_softmax(x, dim=1)          # softmax\n",
    "\n",
    "model = GCN(nfeat=features.shape[1], nhid=hidden,\n",
    "            nclass=labels.max().item() + 1,dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "0kahTMY9Z_Ml"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)                         \n",
    "    loss_train = torch.nn.functional.nll_loss(output[idx_train], labels[idx_train])  # loss function\n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train])                       # training accuracy\n",
    "    loss_train.backward()                                                            # backpropagation\n",
    "    optimizer.step()                                                                 # update parameters\n",
    "\n",
    "    if not fastmode:\n",
    "        model.eval()\n",
    "        output = model(features, adj)\n",
    "        \n",
    "    if epoch%50 == 0:\n",
    "        loss_val = torch.nn.functional.nll_loss(output[idx_val], labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "error",
     "timestamp": 1649779667020,
     "user": {
      "displayName": "NH L",
      "userId": "13973463595760031265"
     },
     "user_tz": 240
    },
    "id": "FL0XvF23aCSI",
    "outputId": "c69a7826-a066-4d8b-8f28-f6283e04f7c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.9249 acc_train: 0.2929 loss_val: 1.8946 acc_val: 0.3500 time: 0.0169s\n",
      "Epoch: 0051 loss_train: 1.3579 acc_train: 0.5714 loss_val: 1.4994 acc_val: 0.4967 time: 0.0050s\n",
      "Epoch: 0101 loss_train: 0.7170 acc_train: 0.8500 loss_val: 1.0255 acc_val: 0.7433 time: 0.0050s\n",
      "Epoch: 0151 loss_train: 0.4706 acc_train: 0.9357 loss_val: 0.8474 acc_val: 0.7533 time: 0.0060s\n",
      "Epoch: 0201 loss_train: 0.3713 acc_train: 0.9500 loss_val: 0.7361 acc_val: 0.7767 time: 0.0100s\n",
      "Epoch: 0251 loss_train: 0.3621 acc_train: 0.9643 loss_val: 0.7874 acc_val: 0.7900 time: 0.0060s\n",
      "Epoch: 0301 loss_train: 0.2763 acc_train: 0.9786 loss_val: 0.7895 acc_val: 0.7700 time: 0.0060s\n",
      "Epoch: 0351 loss_train: 0.2765 acc_train: 0.9571 loss_val: 0.7135 acc_val: 0.7967 time: 0.0080s\n",
      "Epoch: 0401 loss_train: 0.3006 acc_train: 0.9357 loss_val: 0.7293 acc_val: 0.7833 time: 0.0060s\n",
      "Epoch: 0451 loss_train: 0.2695 acc_train: 0.9500 loss_val: 0.7460 acc_val: 0.7667 time: 0.0050s\n",
      "Test set results: loss= 0.6156 accuracy= 0.8370\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    output = model(features, adj)                     # features:(2708, 1433)   adj:(2708, 2708)\n",
    "    loss_test = torch.nn.functional.nll_loss(output[idx_test], labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "epochs = 500\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNXGqG6pV3seR0Pmf1nSnzc",
   "collapsed_sections": [],
   "name": "GCN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
